# ai_agent.py
import os
import json
import time
import pandas as pd
from datetime import datetime
from utils.api_helper import call_deepseek_api
from config import AI_MODEL, AGENT_SYSTEM_PROMPT, DATA_PATH
# ai_agent.py (æ–°å¢éƒ¨åˆ†)
from signal_validator import SignalValidator
from config import Signals_path
from config import API_LOG_PATH

def _write_api_log(request_payload, response_text):
    import json
    from datetime import datetime

    entry = {
        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "request": request_payload,
        "response": response_text
    }

    os.makedirs(os.path.dirname(API_LOG_PATH), exist_ok=True)
    with open(API_LOG_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(entry, ensure_ascii=False, indent=2) + "\n")


class AIAgent:
    def __init__(self):
        self.model = AI_MODEL
        self.prompt = AGENT_SYSTEM_PROMPT
        # Use the centralized Signals_path as the single file for both logs and executor input
        self.log_path = Signals_path
        # ensure directory exists for Signals_path
        dirpath = os.path.dirname(Signals_path)
        if dirpath:
            os.makedirs(dirpath, exist_ok=True)

    # ------------------------------------------------------
# ğŸ¤– AI æ™ºèƒ½äº¤æ˜“ Agent
# ==========================================================
class AIAgent:
    def __init__(self):
        self.model = AI_MODEL
        self.prompt = AGENT_SYSTEM_PROMPT
        # Use the centralized Signals_path as the single file for both logs and executor input
        self.log_path = Signals_path
        # ensure directory exists for Signals_path
        dirpath = os.path.dirname(Signals_path)
        if dirpath:
            os.makedirs(dirpath, exist_ok=True)

    # ------------------------------------------------------
    # æ¯æ—¥ç”Ÿæˆäº¤æ˜“ä¿¡å·
    # ------------------------------------------------------

        
    def generate_signals(self, daily_data: dict, positions: dict):
        """
        daily_data: {symbol: {æŒ‡æ ‡...}}
        positions: å½“å‰æŒä»“ä¿¡æ¯
        """
        print("ğŸ¤– æ­£åœ¨è°ƒç”¨ AI æ¨¡å‹ç”Ÿæˆäº¤æ˜“ä¿¡å·...")
        # normalize today to a string to avoid Timestamp serialization issues
        today = list(daily_data.values())[0]["daily"]["Date"]
        if isinstance(today, (pd.Timestamp, datetime)):
            today = today.strftime("%Y-%m-%d")
        else:
            try:
                # if it's an array-like (e.g. numpy), try to convert
                today = str(today)
            except Exception:
                today = ""

        formatted = {}
        for sym, data in daily_data.items():
            formatted[sym] = {
                "daily": {k: v for k, v in data["daily"].items() if k not in ["Open", "High", "Low"]},
                "weekly": data["weekly"],
                "monthly": data["monthly"],
            }

        # JSON can't serialize pandas.Timestamp/datetime objects by default.
        # Recursively convert any Timestamp/datetime/numpy types to strings or scalars.
        def _make_serializable(obj):
            # pandas Timestamp
            if isinstance(obj, (pd.Timestamp, datetime)):
                return obj.strftime("%Y-%m-%d")
            # numpy scalar types
            try:
                import numpy as _np

                if isinstance(obj, _np.generic):
                    return obj.item()
            except Exception:
                pass
            # dict -> recurse
            if isinstance(obj, dict):
                return {k: _make_serializable(v) for k, v in obj.items()}
            # list/tuple -> recurse
            if isinstance(obj, (list, tuple)):
                return [_make_serializable(v) for v in obj]
            # fallback: leave as-is
            return obj

        formatted_safe = _make_serializable(formatted)
        positions_safe = _make_serializable(positions)

        formatted_data = json.dumps(formatted_safe, indent=2, ensure_ascii=False)
        formatted_positions = json.dumps(positions_safe, indent=2, ensure_ascii=False)

        # Build the user prompt without using an f-string to avoid accidental
        # interpolation of literal JSON braces in the sample output block.
        user_prompt = (
            "Here is the information you need:\n"
            "Today is "
            + str(today)
            + ".\nBelow is today's stock data (read from the processed CSV files):\n\n"
            + formatted_data
            + "\n\nCurrent positions are as follows:\n"
            + formatted_positions
            + "\n\nPlease analyze the short-term and mid-term trends for each stock and output BUY/SELL/HOLD signals.\n"
            + "Only output valid JSON arrays, do not explain your thinking process\n"
            + "          such as:\n"
            + "          [\n"
            + "            {\"symbol\": \"QQQ\", \"action\": \"HOLD\", \"confidence\": 0.70, \"reason\": \"Strong uptrend but RSI approaching overbought, MACD momentum slowing\"},\n"
            + "            {\"symbol\": \"TMUS\", \"action\": \"BUY\", \"confidence\": 0.65, \"reason\": \"Oversold daily RSI, potential reversal setup with price below EMA20\"},\n"
            + "            {\"symbol\": \"GLD\", \"action\": \"SELL\", \"confidence\": 0.75, \"reason\": \"Extremely overbought RSI on weekly and daily, high risk of pullback\"},\n"
            + "            {\"symbol\": \"NVO\", \"action\": \"BUY\", \"confidence\": 0.60, \"reason\": \"Neutral RSI with potential bottoming pattern, MACD turning positive\"}\n"
            + "          ]\n"
        )

        # âŒ ä¸å†æ‰“å° verbose
        response = call_deepseek_api(
            model=self.model,
            system_prompt=self.prompt,
            user_prompt=user_prompt,
            timeout=300,
            retries=3,
            verbose=False
        )

        # âœ… å†™å…¥ API è¾“å…¥ & è¾“å‡ºæ—¥å¿—
        _write_api_log(
            request_payload={
                "model": self.model,
                "system_prompt": self.prompt,
                "user_prompt": user_prompt
            },
            response_text=response
        )


        # å¦‚æœå“åº”ä¸ºç©ºå­—ç¬¦ä¸²æˆ–ä»…åŒ…å«ç©ºç™½ï¼Œç»™å‡ºæ›´æ˜ç¡®çš„è¯Šæ–­å¹¶è·³è¿‡è§£æ
        if not response or (isinstance(response, str) and response.strip() == ""):
            print("âŒ API è¿”å›ç©ºå“åº”ï¼ˆé•¿åº¦ä¸º0æˆ–ä»…ç©ºç™½ï¼‰ã€‚è¿™å¯èƒ½è¡¨ç¤ºæ¨¡å‹è¿”å›äº†ç©ºå†…å®¹ï¼Œæˆ–æœåŠ¡å™¨è¿”å›äº†ç©ºä½“ã€‚")
            df = pd.DataFrame(columns=["symbol", "action", "confidence", "reason", "Date"])
        else:
            # å°è¯•è§£æ API è¿”å›çš„ JSONï¼›è‹¥è§£æå¤±è´¥ï¼ˆä¾‹å¦‚ API é”™è¯¯æˆ–ä½™é¢ä¸è¶³ï¼‰ï¼Œåˆ›å»ºç©ºçš„ signals DataFrame
            try:
                parsed = json.loads(response)
                df = pd.DataFrame(parsed)
                df["Date"] = today
                print("âœ… AI å†³ç­–è¾“å‡º (parsed JSON raw):")
                try:
                    # print the parsed JSON array in full
                    print(json.dumps(parsed, ensure_ascii=False, indent=2))
                except Exception:
                    print(repr(parsed))

                # print("âœ… AI å†³ç­–è¾“å‡º (DataFrame, full):")
                # try:
                #     # print full dataframe without pandas truncation
                #     print(df.to_string(index=False))
                # except Exception:
                #     print(df)
            except Exception as e:
                print("âŒ AI è¾“å‡ºè§£æå¤±è´¥:", e)
                # æ‰“å°åŸå§‹å“åº”å…¨æ–‡ä»¥ä¾¿æ’æŸ¥
                df = pd.DataFrame(columns=["symbol", "action", "confidence", "reason", "Date"])

        # === éªŒè¯ä¿¡å· ===
        validator = SignalValidator(positions)
        df_valid = validator.validate_signals(df)

        print("âœ… æœ€ç»ˆå¯æ‰§è¡Œä¿¡å·:")
        print(df_valid)
        return df_valid

    # ------------------------------------------------------
    # ä¿å­˜ä¿¡å·æ—¥å¿—
    # ------------------------------------------------------
    def save_signals(self, df):
        # If nothing to save, skip
        if df.empty:
            return

        # Build executor-ready rows from incoming df (which is the validated signals)
        out_rows = []
        for _, row in df.iterrows():
            symbol = str(row.get("symbol", "")).upper()
            action = str(row.get("action", "")).upper()
            try:
                confidence = float(row.get("confidence", 0) or 0)
            except Exception:
                confidence = 0.0
            reason = row.get("reason", "") or ""
            date = row.get("Date", "")

            price = None
            # Try to fetch Close price for the given date from processed CSV
            try:
                proc_path = os.path.join("processed", f"{symbol.lower()}_daily_clean.csv")
                if os.path.exists(proc_path):
                    dfp = pd.read_csv(proc_path, parse_dates=["Date"]) 
                    # match by date; allow date string or Timestamp
                    if isinstance(date, str):
                        match_date = pd.to_datetime(date).date()
                    elif hasattr(date, "date"):
                        match_date = pd.to_datetime(date).date()
                    else:
                        match_date = None

                    if match_date is not None:
                        rowp = dfp[dfp["Date"].dt.date == match_date]
                        if not rowp.empty and "Close" in rowp.columns:
                            price = float(rowp.iloc[-1]["Close"])
            except Exception:
                price = None

            out_rows.append({
                "Symbol": symbol,
                "Action": action,
                "Confidence": confidence,
                "Reason": reason,
                "Date": date,
                "Price": price
            })

        df_signals = pd.DataFrame(out_rows)

        # Normalize text columns
        if not df_signals.empty:
            df_signals["Symbol"] = df_signals["Symbol"].astype(str).str.upper()
            df_signals["Action"] = df_signals["Action"].astype(str).str.upper()

        # Merge with existing Signals_path (single source of truth) and dedupe by Symbol/Action/Date keeping latest
        try:
            if os.path.exists(Signals_path):
                existing = pd.read_csv(Signals_path)
                combined = pd.concat([existing, df_signals], ignore_index=True)
            else:
                combined = df_signals

            # Normalize before dedupe
            if not combined.empty:
                if "Symbol" in combined.columns:
                    combined["Symbol"] = combined["Symbol"].astype(str).str.upper()
                if "Action" in combined.columns:
                    combined["Action"] = combined["Action"].astype(str).str.upper()

                # Drop duplicates keeping the latest occurrence
                combined = combined.drop_duplicates(subset=["Symbol", "Action", "Date"], keep="last")

            combined.to_csv(Signals_path, index=False)
            written = len(combined)
        except Exception:
            # On any failure, fallback to writing only the new batch
            df_signals.to_csv(Signals_path, index=False)
            written = len(df_signals)

        print(f"ğŸ“ å·²å†™å…¥åˆå¹¶ä¿¡å·æ–‡ä»¶: {Signals_path} (å…± {written} æ¡)")


